import json

from virtool_workflow import cleanup, step

import utils
from utils import prepare_export_otus


@step
async def write_fasta(index, reference, fasta_path):
    """
    Generates a FASTA file of all sequences in the reference database. The FASTA headers are
    the sequence IDs.

    TODO: Upload FASTA file
    TODO: Ensure sequence_otu_map is generated by index from index fixture. Delete this step?

    """
    sequence_otu_map = dict()

    sequences = utils.get_sequences_from_patched_otus(
        index.otus,
        reference.data_type,
        sequence_otu_map
    )

    await utils.write_sequences_to_file(fasta_path, sequences)


@step
async def bowtie_build(fasta_path, proc, reference, run_subprocess, work_path):
    """
    Run a standard bowtie-build process using the previously generated FASTA reference.

    Do not run the build if the reference contains barcode targets. Amplicon workflows do not use
    Bowtie2 indexes. The root name for the new reference is 'reference'.

    """
    if reference.data_type != "barcode":
        command = [
            "bowtie2-build",
            "-f",
            "--threads", str(proc),
            str(fasta_path),
            str(work_path / "reference")
        ]

        await run_subprocess(command)


@step
async def upload(fasta_path, index, run_in_executor):
    """
    Replaces the old index with the newly generated one.

    TODO: Upload all files.

    """
    await index.upload_fasta(fasta_path)
    await index.finalize()


@step
async def build_json(index, reference, run_in_executor, work_path):
    """
    Create a reference.json.gz file at ``<data_path>/references/<ref_id>/<index_id>``.

    TODO: Make sure upload matches API. It most certainly doesn't here.

    """
    data = {
        "otus": prepare_export_otus(index.otus),
        "data_type": reference.data_type,
        "organism": reference.organism,
        "targets": reference.targets
    }

    json_path = work_path / "reference.json.gz"

    await run_in_executor(
        utils.compress_json_with_gzip,
        json.dumps(data),
        json_path
    )

    # Compress the JSON string to a gzip file.
    await index.upload_json(json_path)


@cleanup
async def delete_index(index):
    """
    Removes the nascent index document and directory.
    """
    await index.delete()



